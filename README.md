
# Challenge 1B - PDF Section Extraction using ML

This project is designed to **extract and rank relevant sections from academic or business PDFs** using machine learning models and sentence embeddings. It supports multiple collections (`Collection_1`, `Collection_2`, etc.) and is packaged with Docker for easy portability.

---

## ğŸ§  Project Highlights

- Uses **Decision Tree classifier** to detect section headings.
- Leverages **Sentence-BERT (MiniLM-L6-v2)** for semantic ranking.
- Extracts top **N relevant sections and paragraphs** based on a task query.
- Processes PDFs in **parallel** for fast execution.
- Accepts JSON input and writes structured JSON output.

---

## ğŸ—‚ï¸ Folder Structure

```
.
â”œâ”€â”€ Collection_1/
â”‚   â”œâ”€â”€ pdfs/
â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â””â”€â”€ challenge1b_output.json
â”œâ”€â”€ Collection_2/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Collection_3/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ all-MiniLM-L6-v2/
â”œâ”€â”€ MyModel.joblib
â”œâ”€â”€ MyEncoder.joblib
â”œâ”€â”€ process_sections.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

---

## âš™ï¸ Core Pipeline

### ğŸ”¹ `process_sections.py` Steps

1. **Input**: JSON containing persona, task, and PDF filenames.
2. **Parse PDFs**: Using `PyMuPDF`, extract lines with formatting features.
3. **Predict**: Use ML model and encoder to classify headings.
4. **Rank**: Use SBERT to compute similarity between task and headings.
5. **Extract Subsections**: Select top paragraphs based on semantic similarity.
6. **Output**: Structured JSON with top sections and refined content.

---

## ğŸ‹ Docker Instructions

### ğŸ”¨ Build the Docker Image

```bash
docker build --platform=linux/amd64 -t my1b:latest .
```

### ğŸš€ Run the Container

```bash
docker run --rm -v ${PWD}/Collection_1:/app/Collection_1 my1b:latest python process_sections.py Collection_1
```

Replace `Collection_1` with the desired folder name (must include `challenge1b_input.json` and `pdfs/`).

---

## ğŸ“¦ Requirements

Install dependencies locally (for development):

```bash
pip install -r requirements.txt
```

### Key Libraries Used

- `sentence-transformers`
- `scikit-learn`
- `PyMuPDF`
- `pandas`, `numpy`, `joblib`, `concurrent.futures`, `torch`

---

## ğŸ“¤ Input JSON Format (`challenge1b_input.json`)

```json
{
  "persona": { "role": "PhD Researcher" },
  "job_to_be_done": { "task": "Study cancer biomarkers" },
  "documents": [
    { "filename": "paper1.pdf" },
    { "filename": "paper2.pdf" }
  ]
}
```

## ğŸ“¥ Output JSON Format (`challenge1b_output.json`)

Includes ranked headings and refined paragraphs.

---

## ğŸ‘¨â€ğŸ’» Author

Nayan Dhamane  
Third Year B.E. Computer Engineering, SPPU (Batch 2026)
